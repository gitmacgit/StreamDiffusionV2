
model_id: "stabilityai/sdxl-turbo"

# Core StreamDiffusion parameters
t_index_list: [1]
width: 512
height: 512
device: "cuda"
dtype: "float16"

# Generation parameters (defaults, can be updated via OSC)
guidance_scale: 1.0
num_inference_steps: 50
seed: 2416333
delta: 1.0

# Prompt configuration (supports both single and blending)
prompt: "default fancy banana"
negative_prompt: "only work with cfg = full"

# Optimization settings
mode: "img2img"  # Always use img2img engines (mode switching handled at runtime)
frame_buffer_size: 1
use_denoising_batch: true
use_lcm_lora: true
use_tiny_vae: true
acceleration: "tensorrt"
cfg_type: "self"
do_add_noise: true
warmup: 10
use_safety_checker: false
skip_diffusion: false
compile_engines_only: false
build_engines_if_missing: true

# Image filtering (similar frame skip)
enable_similar_image_filter: false
similar_image_filter_threshold: 0.99
similar_image_filter_max_skip_frame: 1

# HuggingFace cache directory (for model downloads)
hf_cache: ""

# TensorRT engine directory
engine_dir: "C:/Users/mac/Documents/Derivative/GIT/StreamDiffusionV2/engines/td"

# ControlNet configuration
use_controlnet: true
controlnets:
  - model_id: "xinsir/controlnet-depth-sdxl-1.0"
    conditioning_scale: 0.0
    preprocessor: "depth_tensorrt"
    preprocessor_params:
      engine_path: "C:/Users/mac/Documents/Derivative/GIT/StreamDiffusionV2/engines/td/preprocessors"
    enabled: true

# IPAdapter configuration
use_ipadapter: true
ipadapters:
  - ipadapter_model_path: "h94/IP-Adapter/sdxl_models/ip-adapter_sdxl.bin"
    image_encoder_path: "h94/IP-Adapter/sdxl_models/image_encoder"
    scale: 0.0
    enabled: true
    type: regular





# TouchDesigner specific settings
td_settings:
  # OSC communication
  osc_receive_port: 8567
  osc_transmit_port: 8577
  
  # Memory interface
  input_mem_name: "StreamDiffusionTD_512-512"
  output_mem_name: "StreamDiffusionTD_512-512_out"
  
  # Debug settings
  debug_mode: true
